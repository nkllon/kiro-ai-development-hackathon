#!/usr/bin/env python3
"""
Live Fire Test - Enhanced Learning Capabilities

Test the enhanced learning features with real project registry data.
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from beast_mode.core.model_registry import ModelRegistry
from beast_mode.core.pdca_models import Pattern


def test_enhanced_learning():
    """Test enhanced learning capabilities"""
    
    print("üéì Testing Enhanced Learning Capabilities")
    print("=" * 60)
    
    # Initialize with real project registry
    registry = ModelRegistry("project_model_registry.json")
    
    print(f"üìä Initial State:")
    print(f"   Total Domains: {len(registry.list_available_domains())}")
    print(f"   Cached Intelligence: {len(registry.intelligence_cache)}")
    
    # Create enhanced learning patterns
    learning_patterns = [
        Pattern(
            pattern_id="enhanced-ghostbusters-001",
            name="Enhanced Ghostbusters Multi-Agent Pattern",
            domain="ghostbusters",
            description="Improved multi-agent coordination with systematic validation",
            implementation_steps=[
                "Initialize multi-agent framework with RM compliance",
                "Implement systematic agent coordination protocols",
                "Add real-time performance monitoring",
                "Enable dynamic agent scaling based on workload",
                "Implement systematic failure recovery"
            ],
            success_metrics={
                "agent_coordination": 0.94,
                "systematic_compliance": 0.91,
                "failure_recovery": 0.88,
                "performance_optimization": 0.92
            },
            confidence_score=0.93
        ),
        Pattern(
            pattern_id="enhanced-linter-001", 
            name="Enhanced Intelligent Linter Pattern",
            domain="intelligent_linter_system",
            description="AI-powered linting with systematic learning",
            implementation_steps=[
                "Implement base linter with RM pattern",
                "Add AI-powered code analysis",
                "Enable systematic pattern learning",
                "Implement real-time feedback loops",
                "Add systematic quality metrics"
            ],
            success_metrics={
                "code_quality_improvement": 0.89,
                "false_positive_reduction": 0.85,
                "learning_accuracy": 0.91,
                "systematic_integration": 0.87
            },
            confidence_score=0.89
        ),
        Pattern(
            pattern_id="enhanced-testing-001",
            name="Enhanced Model-Driven Testing Pattern", 
            domain="model_driven_testing",
            description="Systematic testing with model-driven intelligence",
            implementation_steps=[
                "Implement systematic test generation",
                "Add model-driven test case selection",
                "Enable automatic test maintenance",
                "Implement systematic coverage analysis",
                "Add intelligent test result analysis"
            ],
            success_metrics={
                "test_coverage": 0.96,
                "test_effectiveness": 0.92,
                "maintenance_reduction": 0.78,
                "systematic_validation": 0.94
            },
            confidence_score=0.91
        )
    ]
    
    # Test enhanced learning updates
    print(f"\nüîÑ Testing Enhanced Learning Updates:")
    for i, pattern in enumerate(learning_patterns, 1):
        print(f"\n   Pattern {i}: {pattern.name}")
        
        # Get initial intelligence
        initial_intelligence = registry.get_domain_intelligence(pattern.domain)
        initial_confidence = initial_intelligence.confidence_score
        initial_patterns = len(initial_intelligence.patterns)
        
        print(f"     Initial Confidence: {initial_confidence:.3f}")
        print(f"     Initial Patterns: {initial_patterns}")
        
        # Update learning
        result = registry.update_learning(pattern)
        print(f"     Update Result: {'‚úÖ Success' if result else '‚ùå Failed'}")
        
        if result:
            # Get updated intelligence
            updated_intelligence = registry.get_domain_intelligence(pattern.domain)
            updated_confidence = updated_intelligence.confidence_score
            updated_patterns = len(updated_intelligence.patterns)
            
            print(f"     Updated Confidence: {updated_confidence:.3f} ({updated_confidence - initial_confidence:+.3f})")
            print(f"     Updated Patterns: {updated_patterns} ({updated_patterns - initial_patterns:+d})")
            
            # Show success metrics
            print(f"     Success Metrics:")
            for metric, value in updated_intelligence.success_metrics.items():
                print(f"       ‚Ä¢ {metric}: {value:.3f}")
    
    # Test pattern merging by updating existing pattern
    print(f"\nüîÄ Testing Pattern Merging:")
    improved_pattern = Pattern(
        pattern_id="enhanced-ghostbusters-001",  # Same ID - should merge
        name="Super Enhanced Ghostbusters Pattern",
        domain="ghostbusters", 
        description="Even better multi-agent coordination",
        implementation_steps=[
            "Initialize multi-agent framework with RM compliance",
            "Implement systematic agent coordination protocols", 
            "Add real-time performance monitoring",
            "Enable dynamic agent scaling based on workload",
            "Implement systematic failure recovery",
            "Add predictive scaling algorithms",  # New step
            "Implement cross-agent learning"     # New step
        ],
        success_metrics={
            "agent_coordination": 0.97,  # Improved
            "systematic_compliance": 0.93,  # Improved
            "failure_recovery": 0.91,  # Improved
            "performance_optimization": 0.95,  # Improved
            "predictive_scaling": 0.89  # New metric
        },
        confidence_score=0.96
    )
    
    # Get pre-merge state
    pre_merge_intelligence = registry.get_domain_intelligence("ghostbusters")
    pre_merge_confidence = pre_merge_intelligence.confidence_score
    
    # Update with improved pattern
    merge_result = registry.update_learning(improved_pattern)
    print(f"   Merge Result: {'‚úÖ Success' if merge_result else '‚ùå Failed'}")
    
    if merge_result:
        post_merge_intelligence = registry.get_domain_intelligence("ghostbusters")
        post_merge_confidence = post_merge_intelligence.confidence_score
        
        print(f"   Pre-merge Confidence: {pre_merge_confidence:.3f}")
        print(f"   Post-merge Confidence: {post_merge_confidence:.3f} ({post_merge_confidence - pre_merge_confidence:+.3f})")
        
        # Find the merged pattern
        merged_pattern = next((p for p in post_merge_intelligence.patterns if p.pattern_id == "enhanced-ghostbusters-001"), None)
        if merged_pattern:
            print(f"   Merged Pattern Steps: {len(merged_pattern.implementation_steps)}")
            print(f"   Merged Pattern Metrics: {len(merged_pattern.success_metrics)}")
            print(f"   New Metrics: {[k for k in merged_pattern.success_metrics.keys() if k not in ['agent_coordination', 'systematic_compliance', 'failure_recovery', 'performance_optimization']]}")
    
    # Test learning insights
    print(f"\nüìà Testing Learning Insights:")
    
    # Overall insights
    overall_insights = registry.get_learning_insights()
    print(f"   Overall Insights:")
    print(f"     Total Patterns: {overall_insights['total_patterns']}")
    print(f"     Average Confidence: {overall_insights['avg_confidence']:.3f}")
    print(f"     Domains with Intelligence: {len(overall_insights['domain_insights'])}")
    
    # Top success metrics
    if overall_insights['top_success_metrics']:
        print(f"     Top Success Metrics:")
        for metric, stats in list(overall_insights['top_success_metrics'].items())[:3]:
            print(f"       ‚Ä¢ {metric}: avg={stats['avg']:.3f}, max={stats['max']:.3f}, count={stats['count']}")
    
    # Domain-specific insights
    print(f"\n   Domain-Specific Insights:")
    for domain, insights in list(overall_insights['domain_insights'].items())[:3]:
        print(f"     {domain}:")
        print(f"       Patterns: {insights['pattern_count']}")
        print(f"       Confidence: {insights['avg_confidence']:.3f}")
        print(f"       Metrics: {len(insights['success_metrics'])}")
    
    # Learning trends
    print(f"\n   Learning Trends:")
    for trend in overall_insights['learning_trends']:
        print(f"     ‚Ä¢ {trend}")
    
    # Test performance metrics
    print(f"\n‚ö° Performance Metrics:")
    perf_metrics = registry.get_performance_metrics()
    print(f"   Query Count: {perf_metrics['query_count']}")
    print(f"   Cache Hit Rate: {perf_metrics['cache_hit_rate']:.2%}")
    print(f"   Domains Cached: {int(perf_metrics['domains_cached'])}")
    
    # Final registry stats
    print(f"\nüìä Final Registry Statistics:")
    stats = registry.get_registry_stats()
    print(f"   Total Domains: {stats['total_domains']}")
    print(f"   Cached Intelligence: {stats['cached_intelligence']}")
    print(f"   Cache Hit Rate: {stats['cache_hit_rate']:.2%}")
    print(f"   Last Updated: {stats['last_updated']}")
    
    print(f"\nüéâ Enhanced Learning Test Complete!")
    print(f"   ‚úÖ Pattern merging validated")
    print(f"   ‚úÖ Weighted metrics averaging validated") 
    print(f"   ‚úÖ Confidence scoring enhanced")
    print(f"   ‚úÖ Learning insights generated")
    print(f"   ‚úÖ Performance optimization maintained")
    
    return registry


if __name__ == "__main__":
    registry = test_enhanced_learning()