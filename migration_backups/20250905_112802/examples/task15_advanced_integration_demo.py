#!/usr/bin/env python3
"""
Beast Mode Framework - Task 15 Advanced Integration Demo
Demonstrates UC-12, UC-15, UC-18, UC-19 implementation

This example shows:
- Graceful degradation management with circuit breakers
- Enhanced observability with actionable alerts
- ADR system for decision documentation
- Code quality gates with automated enforcement
"""

import time
import uuid
from datetime import datetime, timedelta
from pathlib import Path

# Import Task 15 components
from src.beast_mode.resilience.graceful_degradation_manager import (
    GracefulDegradationManager, DegradationLevel, CircuitBreakerConfig
)
from src.beast_mode.observability.enhanced_observability_manager import (
    EnhancedObservabilityManager, AlertRule, AlertSeverity, EnforcementLevel
)
from src.beast_mode.documentation.adr_system import (
    ADRSystem, DecisionCategory, DecisionContext, DecisionOption, DecisionConsequence
)
from src.beast_mode.quality.code_quality_gates import (
    CodeQualityGates, QualityRule, QualityCheckType, EnforcementLevel as QualityEnforcement
)

def main():
    """Demonstrate Task 15 advanced integration capabilities"""
    print("üöÄ Beast Mode Framework - Task 15 Advanced Integration Demo")
    print("=" * 70)
    
    # Demo 1: Graceful Degradation Management (UC-12)
    print("\nüõ°Ô∏è  Demo 1: Graceful Degradation Management (UC-12)")
    print("-" * 55)
    
    degradation_manager = GracefulDegradationManager()
    print(f"‚úÖ Degradation Manager initialized")
    print(f"   Status: {degradation_manager.get_module_status()['status']}")
    print(f"   Current degradation level: {degradation_manager.get_system_degradation_level().value}")
    
    # Register services for monitoring
    def healthy_service_check():
        return True
        
    def unhealthy_service_check():
        return False
        
    def fallback_handler(operation, error=""):
        return {"fallback_data": f"Fallback for {operation}", "error": error}
    
    # Register services
    degradation_manager.register_service(
        "critical_service",
        healthy_service_check,
        fallback_handler
    )
    
    degradation_manager.register_service(
        "failing_service",
        unhealthy_service_check,
        fallback_handler
    )
    
    print(f"   ‚úÖ Registered services: critical_service, failing_service")
    
    # Demonstrate circuit breaker functionality
    print("\n   Circuit Breaker Demonstration:")
    
    # Test healthy service
    try:
        with degradation_manager.circuit_breaker("critical_service", "test_operation") as context:
            print(f"   ‚úÖ Critical service operation successful")
            print(f"      Circuit state: {context['circuit_state']}")
    except Exception as e:
        print(f"   ‚ùå Critical service failed: {e}")
    
    # Test failing service (will trigger circuit breaker)
    print("   Simulating service failures...")
    for i in range(6):  # Exceed failure threshold
        try:
            with degradation_manager.circuit_breaker("failing_service", f"operation_{i}"):
                raise Exception(f"Simulated failure {i+1}")
        except Exception:
            pass
    
    print(f"   ‚ö†Ô∏è  Failing service circuit breaker opened")
    
    # Check system degradation
    current_degradation = degradation_manager.get_system_degradation_level()
    print(f"   System degradation level: {current_degradation.value}")
    
    # Get degradation analytics
    analytics = degradation_manager.get_degradation_analytics()
    print(f"   Services monitored: {analytics['current_status']['services_monitored']}")
    print(f"   Circuit breakers open: {analytics['current_status']['circuit_breakers_open']}")
    
    # Demo 2: Enhanced Observability (UC-15)
    print("\nüìä Demo 2: Enhanced Observability with Actionable Alerts (UC-15)")
    print("-" * 65)
    
    observability_manager = EnhancedObservabilityManager()
    print(f"‚úÖ Enhanced Observability Manager initialized")
    print(f"   Status: {observability_manager.get_module_status()['status']}")
    
    # Create alert rules
    cpu_alert_rule = AlertRule(
        rule_id="high_cpu_usage",
        name="High CPU Usage Alert",
        description="Alert when CPU usage exceeds 80%",
        metric_name="cpu_usage_percentage",
        condition="> 0.8",
        threshold_value=0.8,
        severity=AlertSeverity.WARNING,
        evaluation_window=300,
        tags={"component": "system", "priority": "high"}
    )
    
    memory_alert_rule = AlertRule(
        rule_id="critical_memory",
        name="Critical Memory Usage",
        description="Critical alert when memory usage exceeds 95%",
        metric_name="memory_usage_percentage",
        condition="> 0.95",
        threshold_value=0.95,
        severity=AlertSeverity.CRITICAL,
        evaluation_window=60,
        tags={"component": "system", "priority": "critical"}
    )
    
    # Register alert rules
    cpu_result = observability_manager.create_alert_rule(cpu_alert_rule)
    memory_result = observability_manager.create_alert_rule(memory_alert_rule)
    
    print(f"   ‚úÖ Created alert rules:")
    print(f"      - {cpu_result['name']} ({cpu_result['severity']})")
    print(f"      - {memory_result['name']} ({memory_result['severity']})")
    
    # Simulate alert triggering
    print("\n   Alert Management Demonstration:")
    
    # Trigger CPU alert
    cpu_alert_result = observability_manager.trigger_alert(
        "high_cpu_usage", 
        0.85, 
        {"host": "server-01", "process": "beast-mode"}
    )
    
    if cpu_alert_result.get("success"):
        alert_id = cpu_alert_result["alert_id"]
        print(f"   üö® CPU Alert triggered: {alert_id}")
        print(f"      Severity: {cpu_alert_result['severity']}")
        print(f"      Resolution guidance: {cpu_alert_result['resolution_guidance']}")
        
        # Acknowledge alert
        ack_result = observability_manager.acknowledge_alert(
            alert_id, "ops_engineer", "Investigating high CPU usage"
        )
        print(f"   ‚úÖ Alert acknowledged by {ack_result['acknowledged_by']}")
        
        # Resolve alert
        time.sleep(1)  # Simulate investigation time
        resolve_result = observability_manager.resolve_alert(
            alert_id, "ops_engineer", "CPU usage normalized after process optimization"
        )
        print(f"   ‚úÖ Alert resolved (Resolution time: {resolve_result['resolution_time_seconds']:.1f}s)")
    
    # Demonstrate distributed tracing
    print("\n   Distributed Tracing Demonstration:")
    
    # Start a trace
    trace_id = observability_manager.start_trace(
        "user_request_processing",
        "api_service",
        tags={"user_id": "12345", "endpoint": "/api/data"}
    )
    
    if trace_id:
        print(f"   üìç Started trace: {trace_id}")
        
        # Add trace logs
        observability_manager.add_trace_log(
            trace_id, "info", "Request received", {"method": "GET"}
        )
        
        observability_manager.add_trace_log(
            trace_id, "debug", "Database query executed", {"query_time_ms": 45}
        )
        
        # Finish trace
        finish_result = observability_manager.finish_trace(trace_id, "ok")
        print(f"   ‚úÖ Trace completed: {finish_result['duration_ms']:.1f}ms")
    else:
        print(f"   ‚ÑπÔ∏è  Trace not sampled (sampling rate: {observability_manager.trace_sampling_rate})")
    
    # Create operational dashboard
    dashboard_config = {
        "panels": [
            {"type": "graph", "title": "CPU Usage", "metric": "cpu_usage_percentage"},
            {"type": "graph", "title": "Memory Usage", "metric": "memory_usage_percentage"},
            {"type": "counter", "title": "Active Alerts", "metric": "active_alerts_count"},
            {"type": "table", "title": "Recent Traces", "metric": "trace_summary"}
        ],
        "refresh_interval": 30,
        "time_range": "1h"
    }
    
    dashboard_result = observability_manager.create_dashboard(
        "system_overview",
        "System Overview Dashboard",
        dashboard_config
    )
    
    print(f"   üìä Created dashboard: {dashboard_result['name']} ({dashboard_result['panels']} panels)")
    
    # Demo 3: ADR System (UC-18)
    print("\nüìã Demo 3: Architectural Decision Record System (UC-18)")
    print("-" * 58)
    
    adr_system = ADRSystem()
    print(f"‚úÖ ADR System initialized")
    print(f"   Status: {adr_system.get_module_status()['status']}")
    
    # Create decision context for a technology choice
    decision_context = DecisionContext(
        problem_statement="Need to select a message queue technology for high-throughput event processing",
        business_drivers=[
            "Handle 10,000+ messages per second",
            "Ensure message durability",
            "Support horizontal scaling",
            "Minimize operational overhead"
        ],
        technical_constraints=[
            "Must integrate with existing Python services",
            "Support both pub/sub and point-to-point messaging",
            "Provide monitoring and alerting capabilities",
            "Budget limit: $5,000/month"
        ],
        stakeholders=[
            "Engineering Team",
            "DevOps Team", 
            "Product Team",
            "Finance Team"
        ],
        timeline="Decision needed within 2 weeks for Q1 implementation"
    )
    
    # Create ADR
    adr_result = adr_system.create_adr(
        "Message Queue Technology Selection",
        DecisionCategory.TECHNOLOGY,
        decision_context,
        ["tech_lead", "senior_engineer", "devops_lead"]
    )
    
    adr_id = adr_result["adr_id"]
    print(f"   ‚úÖ Created ADR: {adr_result['title']} ({adr_id})")
    print(f"      Status: {adr_result['status']}")
    print(f"      Stakeholders: {len(decision_context.stakeholders)}")
    
    # Add decision options
    print("\n   Adding Decision Options:")
    
    # Option 1: Apache Kafka
    kafka_option = DecisionOption(
        option_id="apache_kafka",
        title="Apache Kafka",
        description="Distributed streaming platform with high throughput capabilities",
        pros=[
            "Excellent performance (millions of messages/sec)",
            "Strong durability guarantees",
            "Rich ecosystem and tooling",
            "Battle-tested in production"
        ],
        cons=[
            "Complex operational overhead",
            "Steep learning curve",
            "Resource intensive"
        ],
        implementation_effort="high",
        risk_level="medium",
        cost_impact="medium",
        technical_debt="low"
    )
    
    # Option 2: Redis Streams
    redis_option = DecisionOption(
        option_id="redis_streams",
        title="Redis Streams",
        description="Redis-based streaming solution with simpler operations",
        pros=[
            "Lower operational complexity",
            "Good performance for moderate loads",
            "Familiar Redis ecosystem",
            "Built-in persistence options"
        ],
        cons=[
            "Lower throughput than Kafka",
            "Less mature streaming features",
            "Single point of failure concerns"
        ],
        implementation_effort="medium",
        risk_level="medium",
        cost_impact="low",
        technical_debt="medium"
    )
    
    # Option 3: Amazon SQS/SNS
    aws_option = DecisionOption(
        option_id="aws_sqs_sns",
        title="Amazon SQS/SNS",
        description="Managed AWS messaging services",
        pros=[
            "Fully managed (no operational overhead)",
            "Automatic scaling",
            "High availability built-in",
            "Pay-per-use pricing"
        ],
        cons=[
            "Vendor lock-in",
            "Higher latency than self-hosted",
            "Limited customization options",
            "Potential cost scaling issues"
        ],
        implementation_effort="low",
        risk_level="low",
        cost_impact="high",
        technical_debt="low"
    )
    
    # Add options to ADR
    for option in [kafka_option, redis_option, aws_option]:
        option_result = adr_system.add_decision_option(adr_id, option)
        print(f"      ‚úÖ Added option: {option.title}")
        print(f"         Implementation effort: {option.implementation_effort}")
        print(f"         Risk level: {option.risk_level}")
        print(f"         Cost impact: {option.cost_impact}")
    
    # Make decision (choosing Kafka for this demo)
    print("\n   Making Decision:")
    
    decision_consequences = DecisionConsequence(
        positive_outcomes=[
            "High-performance message processing capability",
            "Scalable architecture for future growth",
            "Rich monitoring and operational tools",
            "Strong community support and documentation"
        ],
        negative_outcomes=[
            "Increased operational complexity",
            "Higher infrastructure costs initially",
            "Team learning curve for Kafka operations"
        ],
        mitigation_strategies=[
            "Invest in Kafka training for operations team",
            "Start with managed Kafka service (Confluent Cloud) initially",
            "Implement comprehensive monitoring from day one",
            "Create runbooks for common operational tasks"
        ],
        monitoring_requirements=[
            "Message throughput and latency metrics",
            "Consumer lag monitoring",
            "Broker health and performance",
            "Topic partition balance"
        ],
        success_metrics=[
            "Process 10,000+ messages/second consistently",
            "Maintain <100ms p99 latency",
            "Achieve 99.9% message delivery reliability",
            "Zero data loss incidents"
        ]
    )
    
    decision_result = adr_system.make_decision(
        adr_id,
        "apache_kafka",
        "Apache Kafka selected for its proven high-throughput capabilities and rich ecosystem. "
        "While it introduces operational complexity, the performance benefits and scalability "
        "align with our long-term architecture goals. We'll mitigate complexity through managed "
        "services initially and gradual team upskilling.",
        decision_consequences
    )
    
    print(f"   ‚úÖ Decision made: {decision_result['chosen_option']}")
    print(f"      Status: {decision_result['status']}")
    print(f"      Rationale: {decision_result['decision_rationale'][:100]}...")
    
    # Search ADRs
    search_results = adr_system.search_adrs("message queue")
    print(f"\n   üìã Search results for 'message queue': {len(search_results)} ADRs found")
    
    # Get ADR analytics
    analytics = adr_system.get_adr_analytics()
    print(f"   üìä ADR Analytics:")
    print(f"      Total ADRs: {analytics['overview_metrics']['total_adrs']}")
    print(f"      Accepted decisions: {analytics['overview_metrics']['accepted_decisions']}")
    print(f"      Average decision time: {analytics['decision_patterns']['average_decision_time_days']} days")
    
    # Demo 4: Code Quality Gates (UC-19)
    print("\nüîç Demo 4: Code Quality Gates with Automated Enforcement (UC-19)")
    print("-" * 68)
    
    quality_gates = CodeQualityGates(".")
    print(f"‚úÖ Code Quality Gates initialized")
    print(f"   Status: {quality_gates.get_module_status()['status']}")
    print(f"   Project root: {quality_gates.get_module_status()['project_root']}")
    
    # Add custom quality rules
    print("\n   Adding Custom Quality Rules:")
    
    # Security scanning rule
    security_rule = QualityRule(
        rule_id="security_scan",
        name="Security Vulnerability Scan",
        description="Comprehensive security vulnerability detection",
        check_type=QualityCheckType.SECURITY,
        enforcement_level=QualityEnforcement.BLOCKING,
        threshold=1.0,  # No security issues allowed
        command="echo 'Security scan: No vulnerabilities found'",
        tags=["security", "blocking", "critical"]
    )
    
    # Code complexity rule
    complexity_rule = QualityRule(
        rule_id="complexity_check",
        name="Code Complexity Analysis",
        description="Cyclomatic complexity and maintainability check",
        check_type=QualityCheckType.COMPLEXITY,
        enforcement_level=QualityEnforcement.WARNING,
        threshold=0.8,
        command="echo 'Complexity analysis: Acceptable levels'",
        tags=["complexity", "maintainability"]
    )
    
    # Documentation coverage rule
    docs_rule = QualityRule(
        rule_id="documentation_coverage",
        name="Documentation Coverage Check",
        description="Ensure adequate code documentation",
        check_type=QualityCheckType.DOCUMENTATION,
        enforcement_level=QualityEnforcement.ADVISORY,
        threshold=0.7,
        command="echo 'Documentation coverage: 75% (Good)'",
        tags=["documentation", "maintainability"]
    )
    
    # Add rules to quality gates
    for rule in [security_rule, complexity_rule, docs_rule]:
        rule_result = quality_gates.add_quality_rule(rule)
        print(f"      ‚úÖ Added rule: {rule.name}")
        print(f"         Type: {rule.check_type.value}")
        print(f"         Enforcement: {rule.enforcement_level.value}")
        print(f"         Threshold: {rule.threshold * 100}%")
    
    # Run quality checks
    print("\n   Running Quality Checks:")
    
    quality_report = quality_gates.run_quality_checks()
    
    print(f"   üìä Quality Report Generated:")
    print(f"      Report ID: {quality_report.report_id}")
    print(f"      Overall Score: {quality_report.overall_score:.2f}")
    print(f"      Quality Level: {quality_report.quality_level.value}")
    print(f"      Execution Time: {quality_report.execution_time_ms}ms")
    print(f"      Check Results: {len(quality_report.check_results)} checks")
    
    # Show individual check results
    print("\n      Individual Check Results:")
    for result in quality_report.check_results:
        status_icon = "‚úÖ" if result.passed else "‚ùå"
        print(f"         {status_icon} {result.rule_id}: {result.score:.2f} ({result.check_type.value})")
        if not result.passed and result.violations:
            print(f"            Issues: {len(result.violations)} violations found")
    
    # Enforce quality gates
    print("\n   Quality Gate Enforcement:")
    
    enforcement_result = quality_gates.enforce_quality_gates(quality_report)
    
    deployment_status = "üü¢ ALLOWED" if enforcement_result["deployment_allowed"] else "üî¥ BLOCKED"
    print(f"   Deployment Status: {deployment_status}")
    print(f"   Quality Score: {enforcement_result['quality_score']:.2f}")
    print(f"   Quality Level: {enforcement_result['quality_level']}")
    
    if enforcement_result["blocking_issues"] > 0:
        print(f"   ‚ö†Ô∏è  Blocking Issues: {enforcement_result['blocking_issues']}")
        
    if enforcement_result["warning_issues"] > 0:
        print(f"   ‚ö†Ô∏è  Warning Issues: {enforcement_result['warning_issues']}")
    
    if enforcement_result["enforcement_reasons"]:
        print("   Enforcement Reasons:")
        for reason in enforcement_result["enforcement_reasons"]:
            print(f"      - {reason}")
    
    if enforcement_result["recommendations"]:
        print("   Recommendations:")
        for rec in enforcement_result["recommendations"]:
            print(f"      üí° {rec}")
    
    # Get quality analytics
    print("\n   Quality Analytics:")
    
    analytics = quality_gates.get_quality_analytics()
    
    print(f"      Current Status:")
    print(f"         Overall Score: {analytics['current_status']['overall_score']:.2f}")
    print(f"         Quality Level: {analytics['current_status']['quality_level']}")
    print(f"         Trend: {analytics['current_status']['trend']}")
    
    print(f"      Execution Metrics:")
    print(f"         Total Checks: {analytics['execution_metrics']['total_checks']}")
    print(f"         Success Rate: {analytics['execution_metrics']['success_rate']:.1%}")
    print(f"         Security Issues: {analytics['execution_metrics']['security_issues']}")
    
    # Demo 5: Integration Showcase
    print("\nüîó Demo 5: Component Integration Showcase")
    print("-" * 45)
    
    print("   Component Health Summary:")
    components = [
        ("Graceful Degradation", degradation_manager),
        ("Enhanced Observability", observability_manager),
        ("ADR System", adr_system),
        ("Code Quality Gates", quality_gates)
    ]
    
    for name, component in components:
        status = component.get_module_status()
        health_icon = "üü¢" if component.is_healthy() else "üî¥"
        print(f"      {health_icon} {name}: {status['status']}")
    
    # Demonstrate cross-component integration
    print("\n   Cross-Component Integration:")
    
    # Quality gates can trigger degradation
    if quality_report.overall_score < 0.7:
        degradation_manager.force_degradation(
            DegradationLevel.MODERATE,
            f"Quality score {quality_report.overall_score:.2f} below threshold"
        )
        print("      üîÑ Quality issues triggered system degradation")
    
    # Observability can monitor degradation
    if degradation_manager.get_system_degradation_level() != DegradationLevel.NONE:
        degradation_alert = observability_manager.trigger_alert(
            "high_cpu_usage",  # Reuse existing rule for demo
            0.9,
            {"source": "degradation_manager", "level": degradation_manager.get_system_degradation_level().value}
        )
        if degradation_alert.get("success"):
            print("      üìä Degradation state triggered observability alert")
    
    # ADR system can document quality decisions
    if not enforcement_result["deployment_allowed"]:
        print("      üìã Quality gate failure would trigger ADR for process improvement")
    
    print("\n   Integration Benefits Demonstrated:")
    print("      ‚úÖ Graceful degradation prevents cascading failures")
    print("      ‚úÖ Enhanced observability provides actionable insights")
    print("      ‚úÖ ADR system captures architectural decisions")
    print("      ‚úÖ Quality gates enforce code standards")
    print("      ‚úÖ Components work together for system resilience")
    
    # Final summary
    print("\n" + "=" * 70)
    print("üéâ Task 15 Advanced Integration Demo Complete!")
    print("=" * 70)
    
    print("\nKey Capabilities Demonstrated:")
    print("‚Ä¢ UC-12: Graceful degradation with circuit breakers and fallback mechanisms")
    print("‚Ä¢ UC-15: Enhanced observability with actionable alerts and distributed tracing")
    print("‚Ä¢ UC-18: ADR system for systematic decision documentation and tracking")
    print("‚Ä¢ UC-19: Code quality gates with automated enforcement and compliance validation")
    
    print("\nIntegration Highlights:")
    print("‚Ä¢ All components provide consistent health monitoring")
    print("‚Ä¢ Cross-component communication enables system-wide resilience")
    print("‚Ä¢ Automated quality enforcement prevents deployment of poor code")
    print("‚Ä¢ Decision tracking ensures architectural choices are documented")
    print("‚Ä¢ Observability provides insights into system behavior and issues")
    
    print("\nNext Steps:")
    print("‚Ä¢ Integrate components into your application architecture")
    print("‚Ä¢ Customize quality rules and alert thresholds for your needs")
    print("‚Ä¢ Set up dashboards for operational monitoring")
    print("‚Ä¢ Train team on ADR process for decision documentation")
    print("‚Ä¢ Configure deployment pipelines to use quality gates")

if __name__ == "__main__":
    main()